<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c20{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:150.8pt;border-top-color:#000000;border-bottom-style:solid}.c6{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:75.8pt;border-top-color:#000000;border-bottom-style:solid}.c18{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:149.2pt;border-top-color:#000000;border-bottom-style:solid}.c27{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:225pt;border-top-color:#000000;border-bottom-style:solid}.c9{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:90.8pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:40.5pt;border-top-color:#000000;border-bottom-style:solid}.c19{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:53.2pt;border-top-color:#000000;border-bottom-style:solid}.c2{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:163.5pt;border-top-color:#000000;border-bottom-style:solid}.c16{-webkit-text-decoration-skip:none;color:#000000;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-family:"Arial";font-style:normal}.c0{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c4{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Arial";font-style:normal}.c29{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-family:"Arial";font-style:normal}.c8{padding-top:0pt;padding-bottom:12pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c13{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c28{padding-top:0pt;padding-bottom:12pt;line-height:1.7;orphans:2;widows:2;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{border-spacing:0;border-collapse:collapse;margin-right:auto}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c32{background-color:#ffffff;max-width:489.1pt;padding:21.3pt 63.8pt 72pt 42.5pt}.c30{-webkit-text-decoration-skip:none;text-decoration:underline;text-decoration-skip-ink:none}.c3{background-color:#ffffff;font-size:10pt;font-weight:700}.c5{background-color:#ffffff;font-size:10.5pt}.c14{background-color:#ffffff;font-size:10pt}.c31{height:16pt}.c25{height:29pt}.c26{font-weight:700}.c24{font-style:italic}.c23{height:18pt}.c11{height:0pt}.c12{height:19pt}.c22{height:24pt}.c10{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c32"><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c13 c5">Introduction and Objective</span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c14">This project is our contribution to a live kaggle competition by Google. According to Google, The 80/20 rule has proven true for many businesses&ndash; </span><span class="c14 c24">only a small percentage of customers produce most of the revenue.</span><span class="c0">&nbsp;As such, Google&rsquo;s marketing teams are challenged to make appropriate investments in promotional strategies.</span></p><p class="c1 c10"><span class="c0"></span></p><p class="c1"><span class="c0">Therefore, Google gave the task to predict the total revenue generated per customer based on the customer dataset of a Google Analytics Merchandise Store. So that the outcome will lead to more actionable operational changes and finally result in a better use of marketing budgets for them.</span></p><p class="c1 c10"><span class="c0"></span></p><p class="c1"><span class="c0">In short, we have tackled a regression task </span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c13 c5">The Data</span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c0">We are provided with the training dataset of 1.7 million observations with 14 columns. However, a few columns are in JSON format and they required considerable preprocessing to convert into normal flattened format. Each JSON column had many features in itself . We wrote a python script to &nbsp;flattening these JSON into columns. The total number of features after converting these json columns was 60 in number. </span></p><p class="c1 c10"><span class="c0"></span></p><p class="c1"><span class="c14">Since, this is an online store, each observation actually is a session when a user comes online at the store to purchase something. However, a user mkay or may not cause any transaction, he could just visit the store for browsing purposes. When a user does not purchase anything , the column </span><span class="c3">totals.transactionRevenue</span><span class="c0">&nbsp;( Dependant feature or target feature that we need to predict) is 0 , else it generates some revenue ( non zero ). Also, each observation has other attributes / columns such as : device.browser , device.language, device.operatingSystem city, country, continent, date, visitStartTime, latitude , longitude etc. </span></p><p class="c1 c10"><span class="c0"></span></p><p class="c1"><span class="c14 c24 c30">Partitioning of data</span><span class="c14">&nbsp;- 1.7 million observations in the training set and 0.4 million observations in the testing set, provided by the kaggle competition creators. Additionally, we have divided the training set into training and validation sets to perform 5 fold cross validation. </span><span class="c16 c14">Hence, we finally have 3 datasets: training, validation and testing. &nbsp;</span></p><p class="c1 c10"><span class="c4"></span></p><p class="c1"><span class="c30 c5">Libraries and tools used -</span><span class="c5">&nbsp;For </span><span class="c14">most of the work, we used </span><span class="c14">sklearn</span><span class="c14">, Keras library and weka tool. </span></p><p class="c1"><span class="c14">Most of the times, we used </span><span class="c3">GridSearchCV</span><span class="c14">&nbsp;for Hyperparameter tuning in our models.</span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c16 c5">Features that have missing values :</span></p><p class="c1 c10"><span class="c5 c26 c29"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 442.81px; height: 216.55px;"><img alt="" src="images/image2.png" style="width: 442.81px; height: 216.55px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c14">For feature, &nbsp;missing more than 50% of data, we removed the feature. Other, we imputed the mean for continuous and treated missing values like a new category for categorical features.</span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c5 c16">Country segmentation by Revenue generated :</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.50px; height: 297.00px;"><img alt="" src="images/image3.png" style="width: 490.50px; height: 297.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c16 c5">Feature importance ( using XGBoost):</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.50px; height: 261.31px;"><img alt="" src="images/image1.png" style="width: 547.50px; height: 261.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c10"><span class="c13 c5"></span></p><p class="c1"><span class="c5 c26">Results and Analysis</span></p><p class="c1"><span class="c0">Since we are predicting the natural log of sum of all transactions revenue of the user, we summed up the transaction revenue at user level and took natural log.</span></p><p class="c1"><span class="c0">Now, based on the analysis we have done, we first started with some basic &nbsp;regression techniques for the baseline results. </span></p><p class="c1 c10"><span class="c0"></span></p><a id="t.754371773bac828a4328041a589f351a69ea548b"></a><a id="t.0"></a><table class="c17"><tbody><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c13 c14">Regression Technique used</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c13 c14">RMSE</span></p></td></tr><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c0">Linear Regression</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c0">8.3 </span></p></td></tr><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c0">Polynomial Regression (degree 3):</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c0">4.49</span></p></td></tr><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c0">Decision Tree </span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c0">5.077</span></p></td></tr><tr class="c23"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c0">Random Forest</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c0">3.1</span></p></td></tr><tr class="c23"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c0">XGBoost</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c0">2.9</span></p></td></tr></tbody></table><p class="c1 c10"><span class="c4"></span></p><p class="c1"><span class="c3">Note-</span><span class="c0">&nbsp;In the project status report last month, we reported MSE and not RMSE. However, we are reporting all our results in RMSE in this final report and analysis.</span></p><p class="c1 c10"><span class="c0"></span></p><p class="c8"><span class="c3">The Big challenge</span><span class="c14">- Although we were happy to see the convincing results from our regression techniques (as discussed above) and also we reached among the top 20 percentile in the contest until then, we realized that we had serious issue in terms of data imbalance. In our dataset, The dependant variable( </span><span class="c3">totals.transactionRevenue</span><span class="c14">)</span><span class="c0">&nbsp;is highly imbalanced. The transaction revenue is present only in 1.3 percent of all the sessions( or observations). For the rest, it is 0. As every observation in the dataset is an online session for the purchase in the online store, it means that only 1.3 percent of all the sessions resulted in a purchase of a product and in the rest sessions, customers didn&#39;t purchase anything. </span></p><p class="c8"><span class="c0">As imbalanced data substantially compromises the learning process, we had a detailed discussion with Professor Downey on 21st November. We finalised two strategies to tackle the issue &nbsp;:-</span></p><p class="c8"><span class="c3">1) Resampling the data- </span><span class="c0">As we had a lot of data - 1.7 million observations, it made sense to go for undersampling technique. So, we started removing records from the data where we had zero revenue and simultaneously started evaluating . Undersampling technique definitely improved the results. The best RMSE we got was :</span></p><a id="t.df8803d93c696e64bda1d2f19274e70b4b0f69e2"></a><a id="t.1"></a><table class="c17"><tbody><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c15"><span class="c5 c26">Technique used ( After Undersampling)</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c5 c26">RMSE</span></p></td></tr><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c7"><span class="c0">Random Forest Regressor</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c0">1.65</span></p></td></tr><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c7"><span class="c0">Adaboost Regressor</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c0">2.35</span></p></td></tr><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c7"><span class="c0">Linear Regression</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c0">1.55</span></p></td></tr><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c7"><span class="c0">Decision Tree Regressor</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c0">2.13</span></p></td></tr><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c7"><span class="c0">Keras Sequential Model</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c0">1.52</span></p></td></tr><tr class="c11"><td class="c18" colspan="1" rowspan="1"><p class="c7"><span class="c0">XGBoost</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c15"><span class="c0">1.48</span></p></td></tr></tbody></table><p class="c8 c10"><span class="c4"></span></p><p class="c8"><span class="c5">2)</span><span class="c5 c26">&nbsp;Classification + Regression </span><span class="c5">- ( </span><span class="c5 c24">An idea that helped us get into the top 5 percentile in the contest.</span><span class="c4">) </span></p><p class="c8"><span class="c5">We</span><span class="c5">&nbsp;believed the main issue we have in this challenge is not to predict transaction revenues but more to get those zeros (zero revenue) right when there was no transaction present. Since less than 1.3 % of the sessions have a non-zero revenue, we believed it was important to find those</span><span class="c5">&nbsp;1.3 % acc</span><span class="c5">. </span><span class="c5">The idea of this analysis is to classify non-zero transactions first and do the regression analysis ( predict revenue) &nbsp;only on &nbsp;those non-zero transactions classified by our classifier. And , ofcourse, our regressor is trained on non zero revenue data only.</span></p><p class="c8"><span class="c13 c5">Part A</span></p><p class="c8"><span class="c4">Classifiers used to predict transaction revenue present (label - 1) and transaction revenue not present &nbsp;(zero transaction revenue) - (label - 0). Moreover, we used undersampling techniques to improve our classification problem :</span></p><a id="t.2045d26222aba0baa6becfb2720a8a91a3eb612d"></a><a id="t.2"></a><table class="c17"><tbody><tr class="c25"><td class="c20" colspan="1" rowspan="1"><p class="c8"><span class="c4">Classifiers used</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c8"><span class="c4">&nbsp; Accuracy</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c8"><span class="c4">AUC</span></p></td></tr><tr class="c31"><td class="c20" colspan="1" rowspan="1"><p class="c8"><span class="c4">Adaboost</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c8"><span class="c4">99.42 %</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c8"><span class="c4">73%</span></p></td></tr><tr class="c11"><td class="c20" colspan="1" rowspan="1"><p class="c8"><span class="c14">Logistic Regression (with </span><span class="c3">regularization</span><span class="c0">)</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c8"><span class="c4">99.12 %</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c8"><span class="c4">62%</span></p></td></tr><tr class="c12"><td class="c20" colspan="1" rowspan="1"><p class="c8"><span class="c4">SVM (No Kernel used )</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c8"><span class="c4">99.18 %</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c8"><span class="c4">64%</span></p></td></tr><tr class="c22"><td class="c20" colspan="1" rowspan="1"><p class="c8"><span class="c5">SVM (</span><span class="c5 c26">with RBF Kernel</span><span class="c4">)</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c8"><span class="c4">99.29 %</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c8"><span class="c4">69%</span></p></td></tr></tbody></table><p class="c8 c10"><span class="c4"></span></p><p class="c8"><span class="c5 c26">Note </span><span class="c5">- The very high accuracy is because of the imbalanced dataset. Therefore, we used AUC to compare the results. </span><span class="c5 c26">Also, we used </span><span class="c5 c26 c24">RBF kernel </span><span class="c13 c5">with SVM to improve the SVM performance and regularization with logistic regression for better generalization. With logistic regression, we optimised parameter &lsquo;C&rsquo;,which controls the inverse of the regularization strength, with GridSearchCV.</span></p><p class="c8"><span class="c5 c13">&nbsp;Part B</span></p><p class="c8"><span class="c0">After classifying the data into transaction revenue present (label - 1) and transaction revenue not present &nbsp;(zero transaction revenue) - (label - 0), we predicted the transaction revenue only on classified data with label 1 ( or transaction revenue present) using a Regressor, which was trained on the data that contained non zero transaction revenue.</span></p><a id="t.aa43291173ecb75da25c1858b7fd83912e0b8ecd"></a><a id="t.3"></a><table class="c17"><tbody><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c13 c5">Regression Technique used (on classified label data 1)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c13 c5">&nbsp;Final RMSE </span></p></td></tr><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c5">Random Forest</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c4">1.4</span></p></td></tr><tr class="c11"><td class="c27" colspan="1" rowspan="1"><p class="c7"><span class="c4">XGBoost</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c4">1.14</span></p></td></tr></tbody></table><p class="c1 c10"><span class="c4"></span></p><p class="c1"><span class="c5 c26">Conclusion : Analysing our results, we conclude that although we considered this project to be a simple regression task, we encountered a big challenge of data Imbalance. First, we tried traditional technique of resampling( undersampling) with regression to improve the results. But, the best results we got when we first classified non zero transaction observations as they were only 1.3 % of the total dataset and then predicted ( regression) the revenue for them. &nbsp;Our best ranking on Kaggle was &nbsp;[ &nbsp;/ &nbsp;] top 5 percentile. &nbsp;</span></p><p class="c28"><span class="c5">&nbsp;</span></p></body></html>